<html>

<head>
	<meta charset="UTF-8" />
	<meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0" />
	<link rel="stylesheet" href="example.css" />
	<title>a* 算法演示</title>
</head>

<body>
	<center>
		<canvas id="map-draw"></canvas>
		<br />
		宽<input type="number" id="map-mapX" value="10" />
		高<input type="number" id="map-mapY" value="10" />
		<input type="checkbox" id="map-smooth" />简化
		<input type="range" min=-2.0 max=2.0 value=0.0 step=0.001 style="width: 100%;" id="playbackrate" />简化
	</center>
	<!--<script src="pkg\wasm_odessay_jps.js"></script>
	<script src="example.js"></script>-->
	<br />
	<pre id=spark></pre>
	<canvas width=600 height=200 style=width:100% id=view />
	<script>
		window.onerror = function(a, b, c, d, e) {
			alert([b, c, d, e].join('\n'));
		};
		window.addEventListener('unhandledrejection', function(a) {
			alert(a.reason.message);
		});

	</script>
	<script>
		let source;

		function dump(f) {
			return 'data:text/javascript;base64,' + btoa('(' + f.toString().replace(/[^\x01-\xfe]/g, "?") + ')()');
		}


		function xyz() { // white-noise-processor.js
			// https://zhuanlan.zhihu.com/p/347514286
			const CLIP = 0;
			const BUFSIZE = 4096;
			const pi = Math.PI;
			let rev = new Uint32Array(BUFSIZE); //rev[i]为i的二进制翻转

			function FFT(real, imag, n, inv) //inv为虚部符号，inv为1时FFT，inv为-1时IFFT
			{
				for (let i = 0; i < n; ++i) { //先将real,imag变成最后的样子
					if (i < rev[i]) {
						[real[i], real[rev[i]]] = [real[rev[i]], real[i]];
						[imag[i], imag[rev[i]]] = [imag[rev[i]], imag[i]];
					}
					// spark.innerText += [real[i], imag[i]] + "\n";
				}
				for (let i = 1; i < n; i <<= 1) { //合并区间的长度的二分之一，或者是合并区间的中点
					let wn_real = Math.cos(pi / i),
						wn_imag = inv * Math.sin(pi / i); //原根
					for (let j = 0; j < n; j += (i << 1)) //枚举具体区间，j也就是区间右端点
					{
						let w0_real = 1,
							w0_imag = 0;
						for (let k = 0; k < i; ++k) { //合并
							let x_real = real[j + k],
								x_imag = imag[j + k];
							let y_real = real[i + j + k],
								y_imag = imag[i + j + k];
							[y_real, y_imag] = [
								y_real * w0_real - y_imag * w0_imag,
								y_real * w0_imag + y_imag * w0_real
							];
							real[j + k] = x_real + y_real;
							imag[j + k] = x_imag + y_imag;
							real[i + j + k] = x_real - y_real;
							imag[i + j + k] = x_imag - y_imag;
							// spark.innerText += [i,j  ,k, y_real, y_imag] + "\n";

							[w0_real, w0_imag] = [
								w0_real * wn_real - w0_imag * wn_imag,
								w0_real * wn_imag + w0_imag * wn_real
							];
						}
					}
				}
			}

			// https://zhuanlan.zhihu.com/p/197450738
			let limit = 1;
			let bit = BUFSIZE >> 1;

			// 比特反转排列(bit-reversed order) 算法
			while (limit < BUFSIZE) {
				for (let i = 0; i < limit; i++) {
					rev[i + limit] = rev[i] + bit;
				}

				limit = limit << 1;
				bit = bit >> 1;
			}

			let real1 = new Float32Array(BUFSIZE),
				imag1 = new Float32Array(BUFSIZE);
			let real2 = new Float32Array(BUFSIZE),
				imag2 = new Float32Array(BUFSIZE);

			function pitch(inp, K, that) {
				real1.set(inp, 0);
				imag1.fill(0.0);
				real2.fill(0.0);
				imag2.fill(0.0);
				FFT(real1, imag1, BUFSIZE, 1);
				const U = Math.floor,
					V = x => U(x) + 1;
				if (K >= 9999) {
					for (let i = 0; i < BUFSIZE / 2; i++) {
						let p = i / K;
						if (p > CLIP) {
							real2[i] = real1[U(p)] * (V(p) - p) + real1[V(p)] * (p - U(p));
							imag2[i] = imag1[U(p)] * (V(p) - p) + imag1[V(p)] * (p - U(p));
						}
					}
				} else {
					real2.fill(0.0);
					imag2.fill(0.0);
					for (let i = 0; i < BUFSIZE / 2; i++) {
						let p = i * K;
						if (i > CLIP) {
							real2[U(p)] += real1[i] * (V(p) - p);
							imag2[U(p)] += imag1[i] * (V(p) - p);
							real2[V(p)] += real1[i] * (p - U(p));
							imag2[V(p)] += imag1[i] * (p - U(p));
						}
					}
				}
				for (let i = 0; i < BUFSIZE / 2; i++) {
					real2[i] *= 2;
					imag2[i] *= 2;
				}
				real2.subarray(BUFSIZE / 2, BUFSIZE).fill(0.0);
				imag2.subarray(BUFSIZE / 2, BUFSIZE).fill(0.0);
				that.port.postMessage([
					[real1, imag1],
					[real2, imag2]
				]);
				FFT(real2, imag2, BUFSIZE, -1);
				real2.forEach((v, i) => {
					real2[i] = v / BUFSIZE;
				})
				return real2;
			}

			// ----7-2-5---5-----6-4---2-----------7--2-5---5-----6--4-1-2-----------2-4-5-----5-4---4---2-7---6-5---4-3-2-------1-----7-7-------

			// 7---2---2---1---7-----

			class WhiteNoiseProcessor extends AudioWorkletProcessor {
				constructor() {
					super();
					let that = this;
					this.port.onmessage = function(mess) {
						that.diaozi = mess.data;
					};
					this.buff = new Float32Array(BUFSIZE).fill(0.0);
					this.ptr = 0;
					this.diaozi = 0.0;
				}
				process(inputs, outputs, parameters) {
					try {
						const input = inputs[0];
						const output = outputs[0];
						if (input.length === 0) {
							return true;
						}
						output[0].set(this.buff.subarray(this.ptr, this.ptr + output[0].length), 0);
						this.buff.set(input[0], this.ptr);
						this.ptr += input[0].length;
						if (this.ptr >= BUFSIZE / 2) {
							let tmp = Float32Array.from(this.buff.subarray(0, this.ptr));
							this.buff.copyWithin(0, this.ptr);
							this.buff.set(tmp, this.ptr);
							this.buff.set(pitch(this.buff, Math.pow(2, this.diaozi), this)
								.subarray(this.ptr/2, this.ptr*3/2), 0);
							this.ptr = 0;
						}
						for (let channel = 1; channel < output.length; ++channel) {
							output[channel].set(output[0], 0);
						}
						return true;
					} catch (e) {
						this.port.postMessage(e.stack);
						return false;
					}
				}
			}

			registerProcessor('white-noise-processor', WhiteNoiseProcessor);
			// return pitch(arguments[0], arguments[1]);
		}

		// a = xyz([1, 0, 1, 0, 1, 0, 1, 0], 1);
		// out = a.map(x => x.map(y => y.toFixed(2))).join('\n');
		// out;
		// throw new Error("ok");

		let whiteNoiseNode;

		document.getElementById("map-smooth").addEventListener("click", async function() {
			const audioCtx = new(window.AudioContext || window.webkitAudioContext)();

			const data = await (await fetch("example.ogg")).arrayBuffer();
			const myArrayBuffer = await audioCtx.decodeAudioData(data);
			// Get an AudioBufferSourceNode.
			// This is the AudioNode to use when we want to play an AudioBuffer
			source = audioCtx.createBufferSource();
			// set the buffer in the AudioBufferSourceNode
			source.buffer = myArrayBuffer;
			// connect the AudioBufferSourceNode to the
			// destination so we can hear the sound

			await audioCtx.audioWorklet.addModule(dump(xyz));
			whiteNoiseNode = new AudioWorkletNode(audioCtx, 'white-noise-processor')

			whiteNoiseNode.port.onmessage = function(mess) {
				if (typeof mess.data === "object") {
					graph(mess.data);
				} else {
					spark.innerText = mess.data;
				}
			};

			whiteNoiseNode.addEventListener("processorerror", function(a) {
				alert("error");
			});

			source.connect(whiteNoiseNode).connect(audioCtx.destination);
			source.playbackRate.value = Math.pow(2, playbackrate.value);
			// start the source playing
			source.start();
			let endcall = () => {
				source.disconnect();
				source = audioCtx.createBufferSource();
				// set the buffer in the AudioBufferSourceNode
				source.buffer = myArrayBuffer;
				source.connect(whiteNoiseNode).connect(audioCtx.destination);
				source.playbackRate.value = Math.pow(2, playbackrate.value);
				source.onended = endcall;
				source.start();
			}
			source.onended = endcall;

		});

		let gview = document.getElementById("view").getContext("2d");

		function graph(data) {
			gview.clearRect(0, 0, 600, 200);
			gview.fillStyle = "#f8f8f8";
			gview.fillRect(0, 0, 600, 200);
			let color = ["red", "blue"];
			gview.beginPath();
			for (let i = 0; i < 600; i += 25 / 3) {
				gview.moveTo(i, 0);
				gview.lineTo(i, 200);
			}
			gview.strokeStyle = "grey";
			gview.stroke();
			gview.beginPath();
			for (let i = 0; i < 600; i += 100) {
				gview.moveTo(i, 0);
				gview.lineTo(i, 200);
			}
			gview.strokeStyle = "black";
			gview.stroke();
			data.forEach((arr, i) => {
				let [real, imag] = arr;
				gview.beginPath();
				gview.moveTo(0, 200);
				for (let i = Math.max(1,
							Math.floor(
								(1 / 4 * 261.62) * real.length / 48000
							)),
						I = Math.min(real.length / 2,
							Math.ceil(
								(16 * 261.62) * real.length / 48000
							)); i < I; i++) {
					let p0 = [real[i], imag[i]],
						p1 = [real[real.length - i], imag[real.length - i]];
					let freq = 48000 * i / real.length;
					let cdis = c => Math.sqrt(c[0] * c[0] + c[1] * c[1]);
					let power = (cdis(p0) + cdis(p1)) * 8 / real.length;
					gview.lineTo(300 + 300 * Math.log(freq / 261.62 / 2) / Math.log(8),
						200 - 200 * power);
				}
				gview.moveTo(600, 200);
				gview.closePath();
				gview.strokeStyle = color[i];
				//gview.fillStyle = "#00FF00";
				gview.lineWidth = 1;
				gview.stroke();
				//gview.fill();
			});
			/*
			gview.beginPath();
			gview.moveTo(0, 100);
			for (let i = 1; i < arr.length / 2; i++) {
				let p0 = arr[i],
					p1 = arr[arr.length - i];
				let freq = 48000 * i / arr.length;
				let cdis = c => Math.sqrt( /*c[0] * c[0] + c[1] * c[1]);
				let power = (cdis(p0) + cdis(p1)) / arr.length;
				gview.lineTo(300 + 300 * Math.log(freq / 256) / Math.log(16),
					100 - 100 * power);
			}
			gview.moveTo(600, 100);
			gview.closePath();
			gview.strokeStyle = "#0000FF";
			gview.lineWidth = 1;
			gview.stroke();*/
		}

		document.getElementById("playbackrate").addEventListener("input", function() {
			whiteNoiseNode.port.postMessage(-event.target.value);
			source.playbackRate.value = Math.pow(2, event.target.value);
		});

	</script>
</body>

</html>
